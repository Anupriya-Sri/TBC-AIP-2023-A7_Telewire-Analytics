{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3100511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from datetime import datetime\n",
    "import dill\n",
    "from sklearn import set_config\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cad0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../data/raw/train.csv',  encoding= 'unicode_escape')\n",
    "y_train = train_data[\"Unusual\"]                      #defining the labels\n",
    "X_train = train_data.drop([\"Unusual\"], axis=1)\n",
    "X_train.head()\n",
    "\n",
    "Data_df = pd.read_csv('../../data/raw/data.csv',  encoding= 'unicode_escape')\n",
    "Data = Data_df.drop([\"Unusual\"], axis=1)\n",
    "Data['CellName'].unique()\n",
    "# get unique values of column 'B' as a NumPy array\n",
    "categories = np.unique(Data['CellName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68497817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom transformers\n",
    "class NullEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X.replace(['#¡VALOR!'], np.nan, inplace=True)\n",
    "        X.replace(['#Â¡VALOR!'], np.nan, inplace=True)\n",
    "        return X\n",
    "    \n",
    "class TimeConversation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # convert time to seconds\n",
    "        X['Time'] = X['Time'].astype(str) + ':00'\n",
    "        X['Time'] = pd.to_timedelta(X['Time']).dt.total_seconds()\n",
    "        return X\n",
    "    \n",
    "class ObjectToFloat(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['maxUE_UL+DL'] = X['maxUE_UL+DL'].astype(float)\n",
    "        return X\n",
    "    \n",
    "class OneHotEncoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,categories):\n",
    "        self.categories = categories\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        # Initialize the OneHotEncoder object\n",
    "        one_hot_encoder = OneHotEncoder(categories=[categories])\n",
    "\n",
    "        # Fit and transform the categorical variable using OneHotEncoder\n",
    "        one_hot_encoded = one_hot_encoder.fit_transform(X[['CellName']])\n",
    "\n",
    "        # Convert the sparse matrix to a dense array and create a new dataframe\n",
    "        one_hot_encoded_df = pd.DataFrame(one_hot_encoded.toarray(), columns=one_hot_encoder.get_feature_names_out(['CellName']))\n",
    "\n",
    "        # Concatenate the one hot encoded dataframe with the original dataframe\n",
    "        X = pd.concat([X, one_hot_encoded_df], axis=1)\n",
    "\n",
    "        return X.drop([\"CellName\"], axis=1)\n",
    "\n",
    "class Scaling(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Initialize the StandardScaler object\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Select only the float columns to scale\n",
    "        float_cols = X.select_dtypes(include=['float']).columns.tolist()\n",
    "\n",
    "        # Scale the float columns using StandardScaler and replace the original data with the scaled data\n",
    "        X[float_cols] = scaler.fit_transform(X[float_cols])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f7f6e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('SetNull', NullEncoder()),\n",
       "                ('TimeConversion', TimeConversation()),\n",
       "                ('ObjectToFloat', ObjectToFloat()), ('Scaling', Scaling()),\n",
       "                ('OneHotEncoding',\n",
       "                 OneHotEncoding(categories=array(['10ALTE', '10BLTE', '10CLTE', '1ALTE', '1BLTE', '1CLTE', '2ALTE',\n",
       "       '3ALTE', '3BLTE', '3CLTE', '4ALTE', '4BLTE', '4CLTE', '5ALTE',\n",
       "       '5BLTE', '5CLTE', '6ALTE', '6BLTE', '6CLTE', '6ULTE', '6VLTE',\n",
       "       '6WLTE', '7ALTE', '7BLTE', '7CLTE', '7ULTE', '7VLTE', '7WLTE',\n",
       "       '8ALTE', '8BLTE', '8CLTE', '9ALTE', '9BLTE'], dtype=object)))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "(\"SetNull\",NullEncoder()),\n",
    "(\"TimeConversion\",TimeConversation()),\n",
    "(\"ObjectToFloat\",ObjectToFloat()),\n",
    "(\"Scaling\",Scaling()),\n",
    "(\"OneHotEncoding\",OneHotEncoding(categories=categories))  \n",
    "])\n",
    "pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20eb3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump(pipe, 'PreprocessingPipeline2.0.joblib')\n",
    "\n",
    "with open('PreprocessingPipeline2.0.pkl', 'wb') as f:\n",
    "    dill.dump((pipe,categories), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fefec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pipe.fit_transform(X_train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877744b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddff837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pipe.fit_transform(X_train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(pipe, 'PreprocessingPipeline2.0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297d544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
